\chapter{Conclusion} \label{conclusion}

\epigraph{2in}{People fear death even more than pain. It's strange that they fear death. Life hurts a lot more than death. At the point of death, the pain is over. Yeah, I guess it is a friend.}{Jim Morrison}{}





Protecting operating system kernels from malware that executes with the same privilege level is an extremely challenging task for which, at the moment, there is no winner either from the community of security researchers nor attackers. This fact is mainly due to the nature of the shared environment in which both trusted and malicious code operate.
A mitigation to attacks with kernel level malware can be achieved when trusted code has been isolated and any external attempt to tamper with it will fail. 

Virtualisation technology offers the aforementioned required isolation capabilities, but at the cost of an additional layer referred to as \emph{hypervisor}, on top of which regular operating systems can be executed. Although we are aware of attacks to the hypervisor that can compromise the entire virtualisation infrastructure \cite{hyperattack, Desnos:2011:DHR:1938158.1938205,Embleton:2008:SRN:1460877.1460892, Gebhardt:2008:HPH:2303959.2304226}, we believe that such attacks can occur under assumptions that are stronger than the ones explained in this work, such as physical access or faulty hardware. We demonstrated how the isolation between a hypervisor and a guest operating system can be used to build a non-bypassable protection system against kernel-level malware. Despite some limitations of the described protection system, regarding the type of kernel code that can be protected, the overall attack surface of the target system results dramatically reduced, giving the attacker very few chances to launch malicious operations. 
In general, isolation is a common requirement of all protection strategies dealing with kernel security. 
In traditional systems in which the countermeasure and the code to be protected share the same space and privileges, it is highly unlikely that trusted code will still be executed even after the kernel has been compromised. The claims made by researchers or secure software vendors about the effectiveness of these types of security measures can be achieved if and only if the isolation requirement is fulfilled.
 
We have contributed to this end by designing a framework that sets a protected environment within the target system and enforces the execution of trusted code from the hypervisor. The aforementioned enforcement of trusted code results decoupled from the target system. Therefore, there are no viable ways for an attacker to tamper with the countermeasure in order to postpone security checkings or to circumvent them completely. In our opinion, two important features, both present in the proposed framework, make it suitable for production systems: isolation and performance.

Isolation allows the execution of the trusted code even after the operating system has been compromised. Any countermeasure in place within a compromised kernel cannot be guaranteed to provide the functionality it has been designed for. This was not the case in our framework.  

Moreover, by setting most of the secure environment within the target system, our framework can operate with an almost native performance impact. 
The countermeasures related to kernel attacks we propose in this work have been designed with performance and size of instrumentation code in mind. Despite the improvements in hardware supported virtualisation technology, we believe that another fundamental property that can impede a security measure's chances of competing in the marketplace is the complexity of integrating it into existing solutions.
The hybrid approach - extensively used in the countermeasures presented in this work - of extending the target kernel with a trusted module that bridges communication to the hypervisor is revealed to be an effective strategy that can be considered even for those systems that cannot be modified for intellectual property reasons or because their source code is not available. Once the trusted module is no longer needed, it is unloaded from the target kernel in order to remove it from the attack surface and to reduce the chances of circumvention even further.

Another area we focus on belongs to the field of web browser security, a topic discussed in the second part of the thesis.
Owing to the recent transformation of the web browser into one of the most important elements in today's computer 
usage and a recent \emph{heap-based} attack that can circumvent some of the most effective countermeasures, we developed a lightweight security measure that not only revealed to be effective but it is also affected by negligible performance impact. We focused on \emph{heap-spraying} attacks, by which objects of malicious content can be allocated on the browser's heap via script languages such as Javascript. An essential requirement to deploy heap-spraying attacks successfully is homogeneity of data. When the malicious object has been allocated in the form of a homogeneous array, it becomes relatively easy for an attacker to forward the instruction pointer of the running system to a location within the aforementioned array and start execution of its content.
By introducing diversity via random interruptions of special bytes we can successfully prevent the execution of malicious code stored on the heap. 

Another challenging aspect when shifting to a newer technology involves designing countermeasures that can take 
advantage of the new features and can be easily integrated with the purpose of improving both performance and security. We contributed to this end by providing a strategy to integrate secure web browsers with hypervisor technology. This might have an impact in those cases in which applications are delivered on demand, as in a \emph{desktop virtualisation} setting.



\section{Drawbacks of virtualization: a case study}\label{virt:drawback}
The types of countermeasures proposed in this work have been designed to work together with the operating system.  The very nature of virtualisation technology relies on the regular mechanisms of guest operating system kernel such as task switching, changes to control registers and other specific events that trigger the hypervisor's intervention.
According to the benchmarks of each virtualisation-based countermeasure explained in this work, their performance impact results, in general, relatively low. One of the keys of this limited performance impact consists in the fact that the countermeasure's code is executed at a specific time, taking advantage of the regular delays imposed by virtualisation technology. Setting the performance penalty of the countermeasure aside, for instance, the VM exit - VM entry mechanism contributes to maintain the overall performance impact close to the lower bound introduced by the technology. 

As we show later in this section, when such a strategy is not applied, the performance impact of the countermeasure will likely be summed up as the performance impact of the virtualisation technology. We observe that if hypervisor's intervention is triggered whenever required, without synchronizing with the operating system, the overall performance impact will result dramatically increased. One such scenario occurred when we examined the possibility of using virtualisation technology to implement a countermeasure that protects against buffer overflows, specifically \emph{return-address attacks}. 

Despite a plethora of available research in the field, the buffer overflow is still one of the most insidious vulnerabilities affecting software nowadays. According to the NIST's National Vulnerability Database\cite{nist}, 587 (10\% of all reported vulnerabilities) buffer overflow vulnerabilities were reported in 2008. Almost 90\% of those vulnerabilities had a high severity rating.
A buffer overflow is the result of stuffing more data into a buffer than it can handle and may allow an attacker to control the execution flow of the attacked program. In a \emph{return-address attack} the attacker exploits a buffer overflow vulnerability to change the return address of a function. It is often performed together with code injection through \emph{shellcode}. 
The execution of arbitrary code is what results in the high severity rating of most of the reported vulnerabilities. These types of attacks are known as stack-based buffer overflow attacks.

A typical function that is vulnerable to a buffer overflow is given in Listing \ref{list:vulnerable}

\begin{lstlisting}[caption=A function that is vulnerable to buffer overflow, label= list:vulnerable]
char* vuln_foo(char *msg) {
   char *p;
   char buffer[30];
   p=buffer;
   strcpy(p, msg);
}
\end{lstlisting}    
\vspace{5mm}

The compiler translates this code and provides a standard prologue that saves the frame pointer (FP) to the stack and allocates space for the local variables and a standard epilogue that restores the saved frame and stack pointer (SP), as shown in Listing \ref{list:stdprlepi}.


\begin{lstlisting}[caption=The standard prologue and epilogue of vuln\_foo(), label= list:stdprlepi]
prologue:
   pushl %ebp
   mov %esp, %ebp
   // local variables
   
  (vuln_foo body)

epilogue:
   leave  // copies %ebp into %esp
     	  // restores %ebp from stack
   ret
	   // jump to address on 
           // top of the stack
\end{lstlisting}    
\vspace{5mm}

Our approach to prevent the exploitation of such a vulnerability consists in extending the architecture with few extra instructions, which are emulated by the hypervisor.
%After running performance benchmarks, a high overhead was observed. Our proof-of-concept software implementation illustrates that the proposed approach is feasible, while the hardware implementation does indeed result in a negligible overhead.
%Although the countermeasure introduced by Read-only RAD is considered safer and harder to exploit \footnote{No alterations are possible on the RAR where return addresses are saved. All other areas of the stack are still not protected.} a serious performance drawback must be taken into account. The countermeasure is very expensive because of the need to do two system calls in each function's prologue. A solution to the serious performance penalty introduced might be to implement this strategy using virtualization by adding new instructions to save and restore the return address from a read-only memory.

These instructions are designed to save and restore the return address from a protected memory area.

\begin{lstlisting}[caption=Instrumented assembly code of vuln\_foo(), label= list:instr]
main:
   call init_callretx 
   ...

vuln_foo:
 prologue:
    pushl %ebp
    mov %esp, %ebp
   // local variables
   callx 

	 (vuln_foo body)

 epilogue:
    retx
    leave  // copies %ebp into %esp
          // restores %ebp from stack
    ret    // jump to address on 
           // top of the stack
\end{lstlisting}  

At the beginning of every program, from its main function, a 4KB page is created and protected via the \emph{mprotect} system call. For each function to be protected the two hardware instructions are called at a specific time in order to prevent an attacker to tamper with the return address of the function.

In the proof-of-concept we provide the hardware\footnote{This is hardware instruction with respect to the program to be protected. From a more general view point the added instructions are not implemented by special purpose hardware since they will be emulated by the hypervisor.} instruction 

\begin{itemize}
\item 
\begin{verbatim}
callx
\end{verbatim}

has been added before the call instruction, that will execute the body of the function. It will save the return address onto the protected memory page

while instruction 
\item 
\begin{verbatim}
retx
\end{verbatim}
has been added right before the assembler \texttt{leave} instruction in the function's epilogue. It will restore the return address from the protected memory page onto the stack.
\end{itemize}

Return addresses of nested functions are stored at higher addresses within the page with the aid of a counter that permits to handle return addresses in a \emph{Last-In-First-Out} order. This order will be preserved until the maximum number of nested functions is reached. Clearly this number depends on the size of the \emph{mprotected} page, which is 4KB in our implementation. Since the x86 architecture handles 32-bit addresses and a counter of the same size is required, our countermeasure can handle up to 1023 nested functions.\\

%% Implementation details
We implemented this concept in the Xen hypervisor \cite{xen} and optimized the most time consuming task of writing to the protected memory area. Our idea consists in clearing the write protection bit (WP) in Control Register 0 (CR0) \footnote{CR0 has control flags that modify the basic operation of the processor. WP bit is normally set to prevent supervisor from writing into read-only memory.} before any write operation to a read-only memory and then set it again. 
The Xen hypervisor, which runs in supervisor mode, needs to be able to write to a read-only page from the user space memory. By unsetting the WP in CR0, the memory management unit (MMU) does not check whether the page is read-only or not, allowing the new instruction to write directly. This strategy leads to a performance impact that is dramatically reduced when compared to the usual mechanism that rely on the MMU\footnote{Although Xen has the necessary code to capture illegal instructions, some setup is required to handle the new instructions' opcodes. New code that checks if the opcode we want to emulate occurred has been added. When the new instruction's opcode occurs, the user space program context (\texttt{ctxt} structure) is updated. This is required before calling \texttt{x86\_emulate} which will take the context structure as parameter and performs the emulation.  Before calling this function, the WP bit of \texttt{CR0} must be unset. Thus when \texttt{x86\_emulate} is called, all writes to memory can happen without any fault. New code to emulate the \texttt{callx} and \texttt{retx} instructions in the hypervisor  has been added to \texttt{x86\_emulate.c}.}. 

Since we need to save the return address from the current stack to memory (callx) and from memory back to the stack (retx), we need two functions that move data from one space to the other. As in a regular Linux kernel the \texttt{copy\_to\_user} and \texttt{copy\_from\_user} functions perform this task. A counter is needed to handle nested functions. This variable is incremented in \texttt{callx} and copied to the read-only memory and decremented in \texttt{retx} and copied back to the stack, in order to preserve a LIFO order.

A check if the return address has been altered may be performed before overwriting it with the saved value. However this will lead to a higher overhead in the overall test result. 

\subsection{Evaluation}\label{ins:evaluation}
To test the performance overhead we ran several integer benchmarks from the suite SPEC CPU2000 \cite{spec2000}. We collected results running programs instrumented with the code that implements the countermeasure and without.\\
All tests were run on a single machine with the hardware specifications reported in Table \ref{machinespecs}. 
As mentioned before, the hypervisor used for our implementation is Xen 3.3.0. The GCC 4.2.3 compiler has been modified to instrument assembler code with the new instructions.

Despite the aforementioned optimization strategy, the benchmarks show that this implementation experiences a slow-down between 5x and 30x, depending on the number of functions to be protected in the program. This latency is definitely not acceptable to consider this type of countermeasure in production systems (Table \ref{table:xenres}).

%Memory overhead is 4KB, which is negligible in comparison to memory required by the program itself.

\begin{table} \label{table:xenres}
 \begin{tabular}{ |l | c | r | r |}
    \hline
\textbf{Program} & \textbf{Base r/t(s)}& \textbf{Instr. r/t(s)}& \textbf{Overhead} \\ \hline
 164.gzip & 223 & 3203 & +1336.32\%  \\ \hline
 175.vpr  & 372 &  2892 &  +677.42\% \\ \hline
   176.gcc  & 225 & 2191 &    +873.78\%  \\ \hline
   181.mcf    &640   & 3849 &    +501.41\%  \\ \hline
   186.crafty    &114& 3676&   +3124.56\%  \\ \hline
   256.bzip2   &307 & 5161 &   +1581.11\%  \\ \hline
   300.twolf    &717 & 4007&   +458.86\%  \\
     \hline
  \end{tabular}
  \caption{SPEC CPU2000 benchmark results of Xen implementation}
\end{table}



% \begin{table}  
%\caption{SPEC CPU2000 benchmark results of our implementation in QEMU}
% \begin{tabular}{ |l | c | r | r|}
%    \hline
%\textbf{Program} & \textbf{Base r/t(s)} & \textbf{Instr. r/t(s)} & \textbf{Overhead} \\ \hline
% 164.gzip & 1368 & 1446 & +5.7\%  \\ \hline
%   176.gcc      &     1010 & 1067      & +5.6\%  \\ \hline
%   181.mcf       &    646      &	 701       & 	+8.5\%  \\ \hline
%   186.crafty    &    1542     & 	1656      &	+7.3\%  \\ \hline
%   197.parser  &      2652    & 	 2844     &+7,2\%  \\ \hline
%   255.vortex   &     2458     & 	2606      &	+6\%  \\ \hline
%   256.bzip2    &     1638     & 	1729      &	+5.5\%  \\ \hline
%   300.twolf     &    2316     & 	2399       &	+3.5\%  \\
%     \hline
%  \end{tabular}
%  \end{table}  \label{table:qemures}

Moreover, our countermeasure does not detect if a buffer overflow has occurred since it overwrites the return address of the protected function, without checking if it has been altered.\\
%Is a failed-with-segfault program better than one that repairs the fault and continues its execution as nothing happened?\\ This is still an unanswered question. 
Our implementation allows the protected function to recover its caller's return address and continue its normal execution flow. We are aware that there are cases in which it is better to terminate the attacked program and log that a buffer overflow has occurred. Checking that the protected return address has been tainted on the stack might be implemented with more overhead.\\

\subsection{Discussion}
The main reason for which virtualization technology inflicts such a significant overhead is given by the high number of context switches from the guest to the hypervisor and back. These transitions are needed for the hypervisor to perform the emulation of the special instructions \emph{callx} and \emph{retx}. 
While, at operating system level, these transitions occur a limited number of times (ie. I/O operations, privileged instructions like the ones reported in Table \ref{virt:intelvt}), in this specific case they will occur an additional number of times that depends on how many functions the program is formed by (or equivalently how many times the function to be protected is called). 

Therefore, while our implementation is technically feasible and even faster than RAD \cite{Chiueh:2001:RCT}, a compiler-based countermeasure that provides an equivalent protection, we conclude that it does not have a realistic chance of deployment, except in higher security environments. 


\section{Future work}
Despite the numerous contributions to tackling kernel malware, we believe that further research is needed in this area. In the virtualisation-based rootkit protection system described in Chapter \ref{bubble}, we are aware of a consistent limitation that restricts integrity checking to those kernel objects that stay invariant during the system lifetime. 
Although the proposed countermeasure provides an efficient protection against kernel mode rootkits, we believe that there is still room for improvement. We expect that rootkits with higher complexity might target \emph{variable} data structures not only to circumvent a countermeasure like the one we described, but also to achieve a more complex behaviour and inflict further damage. Therefore, we suggest further research that leads to protecting critical kernel objects that are permitted to change during operating system lifetime, such as task structures created at runtime, structures that can be assigned to multiple values, dynamic kernel pointers, etc. as reported in \cite{dynamicdatakernel}. 
The reader is likely to notice that protecting dynamic kernel data is a much more difficult task for which an approach different from the one proposed for static objects must be considered. 

The trusted code enforcement framework proposed in this thesis can be used to perform the difficult task of rootkit prevention in a more dynamic way. This major flexibility is due to the fact that, despite the isolation layer, the trusted code is executing within the target operating system. The number of applications that may take advantage of such a framework is limited by the needs and reader's imagination. For instance, traditional signature-based anti-malware systems are effective only against known rootkits \cite{Mahapatra:2011:OCV:1988997.1989022} and any attempt to protect against rootkits coded with a different style or targeting unprotected areas of the kernel might fail. Moreover, in case of attack, these systems can be deactivated by the malware itself since they are executing within the same system to be protected. Such anti-malware systems can thus benefit from the secure framework we propose in order to operate within the target system and to stay isolated at the same time, making any attempt to be circumvented extremely difficult or not feasible at all. 
 

%FIXME  We also envisage to extend our framework with techniques to inject security agents into a guest operating system so as to provide secure means of on-demand deployment of such agents.
%TODO future work security of applications delivered on demand 


%\section{Future research opportunities and applications}
To conclude, we identify an area that needs the attention of security researchers in light of virtualisation technology, namely \emph{mobile computing}. The trend of mobile devices outselling traditional computers is a consistent evidence of the drift of computing experience in general \cite{mobilemagic, oulasvirta:habits, 6072199}. Moreover, this popularity is stimulating the spread of malware specifically designed for operating systems that execute on  mobile devices \cite{mobilemalware, mobilemalware2, androidmalware, androidmalware2, iosmalware}.
  
We expect that virtualisation technology will affect the mobile arena in the near future. Hardware support to virtualisation might provide an entirely new way of thinking about security for mobile devices, similarly to what has been observed so far.
For instance, the technology for executing corporate and personal identity on top of the same physical mobile device is already present \cite{mobilevirt}. 
The nature of mobile devices, usually equipped with limited hardware resources (such as less computational power, smaller storage capacity, finite  battery life, etc), may place additional constraints on the design of those security countermeasures that will take advantage of mobile virtualisation technology. 


